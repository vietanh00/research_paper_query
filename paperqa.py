# -*- coding: utf-8 -*-
"""paperQA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vFGBBeC0qCNea_ku_8uwR_xeXfTseoz5

# Environment setup
"""

!pip install transformers

# faiss (Facebook AI Similarity Search) installation is best with conda
!pip install -q condacolab
import condacolab
condacolab.install()
!conda install -c pytorch faiss-gpu

!pip install datasets
!pip install gradio

!pip install transformers[onnx]

"""# Semantic search model: create context"""

import tensorflow as tf
from transformers import TFAutoModelForQuestionAnswering

from transformers import pipeline

from datasets import load_dataset
dataset = load_dataset("csv", data_files="https://raw.githubusercontent.com/vietanh00/research_paper_query/main/arxiv_papers.csv", split="train")
#only keep the title and abstract columns; remove rows with abstract < 30 since those likely won't help
dataset = dataset.filter(lambda x: len(x["abstract"]) > 30)
dataset_columns = dataset.column_names
col_to_keep = ["title", "abstract"]
col_to_delete = ["published","authors","url"]
dataset = dataset.remove_columns(col_to_delete)
dataset

from transformers import AutoTokenizer, TFAutoModel

model_ckpt = "sentence-transformers/multi-qa-mpnet-base-dot-v1"
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)
model = TFAutoModel.from_pretrained(model_ckpt, from_pt=True)

def cls_pooling(model_output):
    return model_output.last_hidden_state[:, 0]

def get_embeddings(text_list):
    encoded_input = tokenizer(
        text_list, padding=True, truncation=True, return_tensors="tf"
    )
    encoded_input = {k: v for k, v in encoded_input.items()}
    model_output = model(**encoded_input)
    return cls_pooling(model_output)

embedding = get_embeddings(dataset["abstract"][0])
embedding.shape

embeddings_dataset = dataset.map(
    lambda x: {"embeddings": get_embeddings(x["abstract"]).numpy()[0]}
)

import faiss
# faiss fails for some reasons
embeddings_dataset.add_faiss_index(column="embeddings")

question = "What is regression?"
question_embedding = get_embeddings([question]).numpy()
scores, samples = embeddings_dataset.get_nearest_examples(
    "embeddings", question_embedding, k=5
)

import pandas as pd

samples_df = pd.DataFrame.from_dict(samples)
samples_df["scores"] = scores
samples_df.sort_values("scores", ascending=False, inplace=True)
relevant_title = []
relevant_abstract = []
for _, row in samples_df.iterrows():
    relevant_title.append(row.title)
    relevant_abstract.append(row.abstract)

"""# Question-answer: distilBERT from created context"""

from transformers import DistilBertTokenizer, TFDistilBertForQuestionAnswering, pipeline
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased-distilled-squad")
model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased-distilled-squad")

context_list = relevant_abstract

inputs = tokenizer(question, relevant_abstract[0], return_tensors="tf")
outputs = model(**inputs)

answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])
answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])

predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
tokenizer.decode(predict_answer_tokens)

q_a = pipeline("question-answering", model='distilbert-base-uncased-distilled-squad')
print("="*50)
print(f">>Possible answers for \"{question}\" include: ")
answer_list = []
for ra in relevant_abstract:
  result = q_a(question=question, context=ra)
  answer_list.append(result['answer'])
print(" -- ".join(answer_list))
print(">>Works regarding this subject include: ")
for rt in relevant_title:
  print(">>>>", rt)

"""# Put gradio"""

import gradio as gr
def answer(question):
  question_embedding = get_embeddings([question]).numpy()
  scores, samples = embeddings_dataset.get_nearest_examples(
    "embeddings", question_embedding, k=5)
  
  samples_df = pd.DataFrame.from_dict(samples)
  samples_df["scores"] = scores
  samples_df.sort_values("scores", ascending=False, inplace=True)
  relevant_title = []
  relevant_abstract = []
  for _, row in samples_df.iterrows():
      relevant_title.append(row.title)
      relevant_abstract.append(row.abstract)

  q_a = pipeline("question-answering", model='distilbert-base-uncased-distilled-squad')
  output = ""
  output += ">>Possible answers for \"" + question + "\" include: \n"
  answer_list = []
  for ct in relevant_abstract:
    result = q_a(question=question, context=ct)
    answer_list.append(result['answer'])
  output += " -- ".join(answer_list)
  output += "\n>>Works regarding this subject include: ", ", ".join(relevant_title)
  return output

demo = gr.Interface(fn=answer, inputs="text", outputs="text")

demo.launch(share=True, debug=True)